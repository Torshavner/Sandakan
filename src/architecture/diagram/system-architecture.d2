title: Rust RAG Pipeline - System Architecture {
  near: top-center
  shape: text
  style.font-size: 20
  style.bold: true
}

direction: right

# Layer 4: Presentation
presentation: Presentation Layer {
  style.fill: "#e3f2fd"

  api: REST API\n(Axum) {
    shape: hexagon
  }

  handlers: Handlers {
    style.fill: "#bbdefb"

    ingest: POST /api/v1/ingest\n(Multipart Upload) {
      shape: rectangle
    }

    chat: POST /v1/chat/completions\n(SSE Streaming) {
      shape: rectangle
    }

    query: POST /api/v1/query\n(RAG Query) {
      shape: rectangle
    }

    jobs: "GET /api/v1/jobs/:id\n(Job Status)" {
      shape: rectangle
    }
  }

  main: main.rs\n(Composition Root) {
    shape: rectangle
  }

  config: Settings\n(Typed Config) {
    shape: rectangle
  }
}

# Layer 3: Infrastructure
infrastructure: Infrastructure Layer {
  style.fill: "#fff3e0"

  persistence: Persistence {
    style.fill: "#ffe0b2"

    qdrant: Qdrant Adapter\n(gRPC) {
      shape: cylinder
    }

    pgJob: PgJobRepository\n(sqlx) {
      shape: cylinder
    }

    pgConv: PgConversationRepository\n(sqlx) {
      shape: cylinder
    }
  }

  llm: LLM {
    style.fill: "#ffe0b2"

    streaming: StreamingLlmClient\n(reqwest + SSE) {
      shape: cloud
    }

    openaiEmbed: OpenAiEmbedder\n(/v1/embeddings) {
      shape: cloud
    }

    localEmbed: LocalCandleEmbedder\n(CPU Inference) {
      shape: cloud
    }
  }

  audio: Audio {
    style.fill: "#ffe0b2"

    candleWhisper: CandleWhisperEngine\n(Local Whisper) {
      shape: document
    }

    openaiWhisper: OpenAiWhisperEngine\n(API) {
      shape: document
    }

    decoder: AudioDecoder\n(Symphonia + Rubato) {
      shape: document
    }
  }

  textProc: Text Processing {
    style.fill: "#ffe0b2"

    fileLoader: CompositeFileLoader\n(PDF + Text) {
      shape: document
    }

    semanticSplit: SemanticSplitter\n(Similarity-based) {
      shape: document
    }

    fixedSplit: RecursiveCharacterSplitter\n(Token-based) {
      shape: document
    }
  }
}

# Layer 2: Application
application: Application Layer {
  style.fill: "#f3e5f5"

  ports: Ports (Traits) {
    style.fill: "#e1bee7"

    fileLoader: FileLoader {
      shape: diamond
    }

    vectorStore: VectorStore {
      shape: diamond
    }

    embedder: Embedder {
      shape: diamond
    }

    llmClient: LlmClient {
      shape: diamond
    }

    textSplitter: TextSplitter {
      shape: diamond
    }

    transcription: TranscriptionEngine {
      shape: diamond
    }

    jobRepo: JobRepository {
      shape: diamond
    }

    convRepo: ConversationRepository {
      shape: diamond
    }
  }

  services: Services {
    style.fill: "#e1bee7"

    ingestion: IngestionService\n(File -> Vectors) {
      shape: rectangle
    }

    worker: IngestionWorker\n(Async Background) {
      shape: rectangle
    }

    retrieval: RetrievalService\n(Query -> Answer) {
      shape: rectangle
    }

    tokenCounter: TokenCounter\n(tiktoken-rs) {
      shape: rectangle
    }
  }
}

# Layer 1: Domain
domain: Domain Layer {
  style.fill: "#e8f5e9"

  entities: Entities {
    style.fill: "#c8e6c9"

    chunk: Chunk\n(ChunkId, DocumentId) {
      shape: oval
    }

    document: Document\n(ContentType) {
      shape: oval
    }

    job: Job\n(JobId, JobStatus) {
      shape: oval
    }

    conversation: Conversation\n(ConversationId) {
      shape: oval
    }

    message: Message\n(MessageId, MessageRole) {
      shape: oval
    }

    embedding: Embedding\n(cosine similarity) {
      shape: oval
    }
  }
}

# External Systems
external: External Systems {
  style.fill: "#ffebee"

  qdrantDB: Qdrant\n(Vector Database) {
    shape: cylinder
    style.stroke: "#d32f2f"
  }

  postgres: PostgreSQL\n(Jobs + Conversations) {
    shape: cylinder
    style.stroke: "#d32f2f"
  }

  openaiAPI: OpenAI API\n(Chat + Embeddings + Whisper) {
    shape: cloud
    style.stroke: "#d32f2f"
  }

  azureAPI: Azure OpenAI\n(Chat Completions) {
    shape: cloud
    style.stroke: "#d32f2f"
  }

  hfHub: Hugging Face Hub\n(Model Downloads) {
    shape: cloud
    style.stroke: "#d32f2f"
  }
}

# Connections - Presentation to Handlers
presentation.api -> presentation.handlers.ingest
presentation.api -> presentation.handlers.chat
presentation.api -> presentation.handlers.query
presentation.api -> presentation.handlers.jobs

# Connections - Infrastructure implements Application Ports
infrastructure.persistence.qdrant -> application.ports.vectorStore: implements
infrastructure.persistence.pgJob -> application.ports.jobRepo: implements
infrastructure.persistence.pgConv -> application.ports.convRepo: implements
infrastructure.llm.streaming -> application.ports.llmClient: implements
infrastructure.llm.openaiEmbed -> application.ports.embedder: implements
infrastructure.llm.localEmbed -> application.ports.embedder: implements
infrastructure.audio.candleWhisper -> application.ports.transcription: implements
infrastructure.audio.openaiWhisper -> application.ports.transcription: implements
infrastructure.textProc.fileLoader -> application.ports.fileLoader: implements
infrastructure.textProc.semanticSplit -> application.ports.textSplitter: implements
infrastructure.textProc.fixedSplit -> application.ports.textSplitter: implements

# Connections - Application Services to Ports
application.services.ingestion -> application.ports.fileLoader: uses
application.services.ingestion -> application.ports.vectorStore: uses
application.services.ingestion -> application.ports.embedder: uses
application.services.ingestion -> application.ports.textSplitter: uses

application.services.worker -> application.ports.fileLoader: uses
application.services.worker -> application.ports.vectorStore: uses
application.services.worker -> application.ports.embedder: uses
application.services.worker -> application.ports.textSplitter: uses
application.services.worker -> application.ports.transcription: uses
application.services.worker -> application.ports.jobRepo: uses

application.services.retrieval -> application.ports.vectorStore: uses
application.services.retrieval -> application.ports.llmClient: uses
application.services.retrieval -> application.ports.embedder: uses
application.services.retrieval -> application.ports.convRepo: uses

# Connections - Services to Domain
application.services.ingestion -> domain.entities.chunk: creates
application.services.ingestion -> domain.entities.document: creates
application.services.worker -> domain.entities.job: updates
application.services.retrieval -> domain.entities.chunk: reads
application.services.retrieval -> domain.entities.conversation: manages
application.services.retrieval -> domain.entities.message: creates

# Connections - Infrastructure to External Systems
infrastructure.persistence.qdrant -> external.qdrantDB: gRPC
infrastructure.persistence.pgJob -> external.postgres: sqlx
infrastructure.persistence.pgConv -> external.postgres: sqlx
infrastructure.llm.streaming -> external.openaiAPI: HTTP/SSE
infrastructure.llm.streaming -> external.azureAPI: HTTP/SSE
infrastructure.llm.openaiEmbed -> external.openaiAPI: HTTP
infrastructure.audio.openaiWhisper -> external.openaiAPI: HTTP
infrastructure.llm.localEmbed -> external.hfHub: model download
infrastructure.audio.candleWhisper -> external.hfHub: model download

# Data Flow Annotations
flows: Data Flows {
  near: bottom-left
  style.fill: "#fffef7"

  ingestion: |md
    **Ingestion:**
    Upload -> Job(Queued) -> Async Worker
    -> MediaExtraction -> Transcribe
    -> Chunk -> Embed -> Store -> Completed
  | {
    shape: text
    style.font-size: 11
  }

  retrieval: |md
    **Retrieval:**
    Query -> Embed -> Search(Top-K)
    -> Token Budget -> Augment -> Stream/Generate
  | {
    shape: text
    style.font-size: 11
  }
}

# Technology Stack
techStack: Tech Stack {
  near: bottom-right
  style.fill: "#fafafa"

  stack: "tokio . axum . sqlx . Qdrant . serde . tracing . candle . symphonia . reqwest" {
    shape: text
    style.font-size: 11
  }
}
